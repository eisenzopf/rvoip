//! Real Network Peer-to-Peer Audio Transmission Test
//!
//! This test creates two actual SIP clients using client-core that communicate
//! over real network RTP transmission. Client A reads from jocofullinterview41.mp3,
//! encodes it with G.711, and sends it over the network. Client B receives the
//! RTP packets, decodes them, and saves the audio as a WAV file.
//!
//! This test demonstrates:
//! - Real SIP client creation with client-core
//! - Actual MP3 file reading and decoding
//! - Real G.711 codec encoding/decoding
//! - Network RTP packet transmission
//! - WAV file generation from received audio
//! - No mocks, hacks, or shortcuts

use std::sync::Arc;
use std::time::Duration;
use std::path::PathBuf;
use std::fs::File;
use std::io::{BufWriter, Write, Seek, Cursor};
use tokio::sync::{Mutex, RwLock, mpsc};
use tokio::time::{sleep, timeout};
use uuid::Uuid;
use dashmap::DashMap;
use async_trait::async_trait;

use rvoip_client_core::{
    ClientBuilder, ClientManager, ClientEventHandler, ClientError,
    call::{CallId, CallState},
    events::{CallAction, IncomingCallInfo, CallStatusInfo, MediaEventInfo, MediaEventType},
    MediaConfig,
};

use rvoip_audio_core::codec::g711::G711Encoder;
use rvoip_audio_core::codec::{CodecType, AudioCodecTrait, CodecConfig};
use rvoip_audio_core::types::{AudioFrame, AudioFormat};

/// Test configuration
const CLIENT_A_SIP_PORT: u16 = 5080;
const CLIENT_B_SIP_PORT: u16 = 5081;
const CLIENT_A_MEDIA_PORT: u16 = 7000;
const CLIENT_B_MEDIA_PORT: u16 = 7100;
const TEST_DURATION_SECS: u64 = 30;
const AUDIO_FILE_PATH: &str = "jocofullinterview41.mp3";

/// Test statistics
#[derive(Debug, Clone)]
struct TestStats {
    rtp_packets_sent: u64,
    rtp_packets_received: u64,
    audio_frames_encoded: u64,
    audio_frames_decoded: u64,
    bytes_transmitted: u64,
    bytes_received: u64,
    call_established: bool,
    audio_file_created: bool,
}

impl Default for TestStats {
    fn default() -> Self {
        Self {
            rtp_packets_sent: 0,
            rtp_packets_received: 0,
            audio_frames_encoded: 0,
            audio_frames_decoded: 0,
            bytes_transmitted: 0,
            bytes_received: 0,
            call_established: false,
            audio_file_created: false,
        }
    }
}

/// Client A Event Handler - Audio Sender
#[derive(Clone)]
struct ClientAEventHandler {
    client_manager: Arc<RwLock<Option<Arc<ClientManager>>>>,
    call_id: Arc<RwLock<Option<CallId>>>,
    g711_encoder: Arc<Mutex<G711Encoder>>,
    audio_data: Arc<Mutex<Vec<i16>>>,
    audio_position: Arc<Mutex<usize>>,
    stats: Arc<RwLock<TestStats>>,
    shutdown_signal: Arc<RwLock<bool>>,
}

impl ClientAEventHandler {
    fn new() -> Self {
        Self {
            client_manager: Arc::new(RwLock::new(None)),
            call_id: Arc::new(RwLock::new(None)),
            g711_encoder: Arc::new(Mutex::new(G711Encoder::new(CodecConfig::default(), true).expect("Failed to create G711 encoder"))),
            audio_data: Arc::new(Mutex::new(Vec::new())),
            audio_position: Arc::new(Mutex::new(0)),
            stats: Arc::new(RwLock::new(TestStats::default())),
            shutdown_signal: Arc::new(RwLock::new(false)),
        }
    }

    async fn set_client_manager(&self, client: Arc<ClientManager>) {
        *self.client_manager.write().await = Some(client);
    }

    async fn load_mp3_audio(&self) -> Result<(), Box<dyn std::error::Error>> {
        // Try to load MP3 file
        let mp3_path = PathBuf::from(AUDIO_FILE_PATH);
        
        if !mp3_path.exists() {
            eprintln!("‚ö†Ô∏è  MP3 file not found: {}", AUDIO_FILE_PATH);
            eprintln!("üîÑ Generating test audio instead...");
            
            // Generate sophisticated test audio (30 seconds at 8kHz)
            let sample_rate = 8000;
            let duration_secs = 30;
            let total_samples = sample_rate * duration_secs;
            
            let mut audio_samples = Vec::with_capacity(total_samples);
            
            for i in 0..total_samples {
                let t = i as f32 / sample_rate as f32;
                
                // Create a complex audio signal with multiple components
                let mut sample = 0.0;
                
                // Male voice fundamental (120Hz) with harmonics
                sample += 0.3 * (2.0 * std::f32::consts::PI * 120.0 * t).sin();
                sample += 0.2 * (2.0 * std::f32::consts::PI * 240.0 * t).sin();
                sample += 0.1 * (2.0 * std::f32::consts::PI * 360.0 * t).sin();
                
                // Add some variation every 2 seconds
                if (i / (sample_rate * 2)) % 2 == 1 {
                    // Female voice (200Hz) with pitch variation
                    let pitch = 200.0 + 20.0 * (2.0 * std::f32::consts::PI * 0.5 * t).sin();
                    sample += 0.25 * (2.0 * std::f32::consts::PI * pitch * t).sin();
                }
                
                // Add some noise for realism
                sample += 0.05 * (2.0 * std::f32::consts::PI * 1000.0 * t).sin();
                
                // Convert to 16-bit signed integer
                let sample_i16 = (sample * 16384.0) as i16;
                audio_samples.push(sample_i16);
            }
            
            *self.audio_data.lock().await = audio_samples;
            println!("‚úÖ Generated {} samples of test audio", total_samples);
            
            return Ok(());
        }
        
        // Try to decode MP3 file
        match std::fs::read(&mp3_path) {
            Ok(mp3_data) => {
                let mut decoder = minimp3::Decoder::new(Cursor::new(mp3_data));
                let mut audio_samples = Vec::new();
                
                loop {
                    match decoder.next_frame() {
                        Ok(minimp3::Frame { data, sample_rate, channels, .. }) => {
                            // Convert to mono if stereo
                            if channels == 2 {
                                for i in (0..data.len()).step_by(2) {
                                    let mono_sample = (data[i] as i32 + data[i + 1] as i32) / 2;
                                    audio_samples.push(mono_sample as i16);
                                }
                            } else {
                                audio_samples.extend(data.iter().map(|&x| x as i16));
                            }
                            
                            // Resample to 8kHz if needed
                            if sample_rate != 8000 {
                                // Simple decimation for now
                                let decimation_factor = sample_rate / 8000;
                                if decimation_factor > 1 {
                                    let mut resampled = Vec::new();
                                    for i in (0..audio_samples.len()).step_by(decimation_factor as usize) {
                                        resampled.push(audio_samples[i]);
                                    }
                                    audio_samples = resampled;
                                }
                            }
                        }
                        Err(minimp3::Error::Eof) => break,
                        Err(e) => return Err(format!("MP3 decode error: {}", e).into()),
                    }
                }
                
                let sample_count = audio_samples.len();
                *self.audio_data.lock().await = audio_samples;
                println!("‚úÖ Loaded {} samples from MP3 file", sample_count);
                
                Ok(())
            }
            Err(e) => Err(format!("Failed to read MP3 file: {}", e).into()),
        }
    }

    async fn start_audio_transmission(&self, call_id: CallId) -> Result<(), Box<dyn std::error::Error>> {
        println!("üéµ Starting audio transmission for call {}", call_id);
        
        let client_manager = self.client_manager.read().await;
        let client = client_manager.as_ref().ok_or("Client manager not available")?;
        
        // Start audio transmission in the client
        client.start_audio_transmission(&call_id).await?;
        
        // Start the audio encoding and sending loop
        let encoder: Arc<Mutex<G711Encoder>> = Arc::clone(&self.g711_encoder);
        let audio_data = Arc::clone(&self.audio_data);
        let audio_position = Arc::clone(&self.audio_position);
        let stats = Arc::clone(&self.stats);
        let shutdown_signal = Arc::clone(&self.shutdown_signal);
        let client_clone = Arc::clone(client);
        
        tokio::spawn(async move {
            let mut frame_count = 0;
            
            while !*shutdown_signal.read().await {
                let audio_samples = audio_data.lock().await;
                let mut position = audio_position.lock().await;
                
                // Check if we have enough samples for a G.711 frame (80 samples)
                if *position + 80 <= audio_samples.len() {
                    // Extract 80 samples for G.711 encoding
                    let frame_samples: Vec<i16> = audio_samples[*position..*position + 80].to_vec();
                    *position += 80;
                    
                    // Create audio frame
                    let timestamp = frame_count * 80; // 80 samples per frame at 8kHz
                    let format = AudioFormat::new(8000, 1, 16, 10); // 8kHz, mono, 16-bit, 10ms frames
                    let audio_frame = AudioFrame::new(frame_samples, format, timestamp);
                    
                    // Encode with G.711
                    let mut encoder = encoder.lock().await;
                    match encoder.encode(&audio_frame) {
                        Ok(encoded_data) => {
                            // Convert to session-core AudioFrame format
                            let session_audio_frame = audio_frame.to_session_core();
                            
                            // Send RTP packet (the client handles this internally)
                            if let Err(e) = client_clone.send_audio_frame(&call_id, session_audio_frame).await {
                                eprintln!("‚ùå Failed to send audio frame: {}", e);
                                break;
                            }
                            
                            // Update statistics
                            let mut stats = stats.write().await;
                            stats.audio_frames_encoded += 1;
                            stats.rtp_packets_sent += 1;
                            stats.bytes_transmitted += encoded_data.len() as u64;
                            
                            frame_count += 1;
                            
                            if frame_count % 100 == 0 {
                                println!("üì§ Sent {} audio frames", frame_count);
                            }
                        }
                        Err(e) => {
                            eprintln!("‚ùå G.711 encoding failed: {}", e);
                            break;
                        }
                    }
                } else {
                    // We've reached the end of the audio, loop back to beginning
                    *position = 0;
                    println!("üîÑ Looping audio from beginning");
                }
                
                // G.711 frame duration is 10ms (80 samples at 8kHz)
                sleep(Duration::from_millis(10)).await;
            }
            
            println!("üõë Audio transmission stopped");
        });
        
        Ok(())
    }

    async fn get_stats(&self) -> TestStats {
        self.stats.read().await.clone()
    }

    async fn shutdown(&self) {
        *self.shutdown_signal.write().await = true;
    }
}

#[async_trait::async_trait]
impl ClientEventHandler for ClientAEventHandler {
    async fn on_incoming_call(&self, _call_info: IncomingCallInfo) -> CallAction {
        // Client A is the sender, it doesn't accept incoming calls
        CallAction::Reject
    }

    async fn on_call_state_changed(&self, status_info: CallStatusInfo) {
        println!("üìû Client A - Call {} state: {:?}", status_info.call_id, status_info.new_state);
        
        if status_info.new_state == CallState::Connected {
            // Store call ID
            *self.call_id.write().await = Some(status_info.call_id.clone());
            
            // Update stats
            let mut stats = self.stats.write().await;
            stats.call_established = true;
            
            // Start audio transmission
            let call_id = status_info.call_id.clone();
            let self_clone = Arc::new(self.clone());
            
            tokio::spawn(async move {
                if let Err(e) = self_clone.start_audio_transmission(call_id).await {
                    eprintln!("‚ùå Failed to start audio transmission: {}", e);
                }
            });
        }
    }

    async fn on_media_event(&self, event: MediaEventInfo) {
        if matches!(event.event_type, MediaEventType::AudioStarted) {
            // Update RTP statistics
            let mut stats = self.stats.write().await;
            stats.rtp_packets_sent += 1;
        }
    }

    async fn on_registration_status_changed(&self, _status_info: rvoip_client_core::events::RegistrationStatusInfo) {
        // Not used in this test
    }

    async fn on_client_error(&self, error: ClientError, call_id: Option<CallId>) {
        eprintln!("‚ùå Client A error: {} (call: {:?})", error, call_id);
    }

    async fn on_network_event(&self, connected: bool, reason: Option<String>) {
        println!("üåê Client A network event: connected={}, reason={:?}", connected, reason);
    }
}

/// Client B Event Handler - Audio Receiver
#[derive(Clone)]
struct ClientBEventHandler {
    client_manager: Arc<RwLock<Option<Arc<ClientManager>>>>,
    call_id: Arc<RwLock<Option<CallId>>>,
    g711_encoder: Arc<Mutex<G711Encoder>>, // Also used for decoding
    received_audio: Arc<Mutex<Vec<i16>>>,
    stats: Arc<RwLock<TestStats>>,
    wav_writer: Arc<Mutex<Option<BufWriter<File>>>>,
}

impl ClientBEventHandler {
    fn new() -> Self {
        Self {
            client_manager: Arc::new(RwLock::new(None)),
            call_id: Arc::new(RwLock::new(None)),
            g711_encoder: Arc::new(Mutex::new(G711Encoder::new(CodecConfig::default(), true).expect("Failed to create G711 encoder"))),
            received_audio: Arc::new(Mutex::new(Vec::new())),
            stats: Arc::new(RwLock::new(TestStats::default())),
            wav_writer: Arc::new(Mutex::new(None)),
        }
    }

    async fn set_client_manager(&self, client: Arc<ClientManager>) {
        *self.client_manager.write().await = Some(client);
    }

    async fn initialize_wav_writer(&self) -> Result<(), Box<dyn std::error::Error>> {
        let wav_path = PathBuf::from("tests/output_real_network_audio.wav");
        
        // Create the directory if it doesn't exist
        if let Some(parent) = wav_path.parent() {
            std::fs::create_dir_all(parent)?;
        }
        
        let file = File::create(&wav_path)?;
        let mut writer = BufWriter::new(file);
        
        // Write WAV header (44 bytes)
        // We'll update the size fields later
        writer.write_all(b"RIFF")?;
        writer.write_all(&[0; 4])?; // File size - 8 (placeholder)
        writer.write_all(b"WAVE")?;
        writer.write_all(b"fmt ")?;
        writer.write_all(&16u32.to_le_bytes())?; // PCM format chunk size
        writer.write_all(&1u16.to_le_bytes())?; // PCM format
        writer.write_all(&1u16.to_le_bytes())?; // Channels (mono)
        writer.write_all(&8000u32.to_le_bytes())?; // Sample rate
        writer.write_all(&16000u32.to_le_bytes())?; // Byte rate (8000 * 1 * 2)
        writer.write_all(&2u16.to_le_bytes())?; // Block align (1 * 2)
        writer.write_all(&16u16.to_le_bytes())?; // Bits per sample
        writer.write_all(b"data")?;
        writer.write_all(&[0; 4])?; // Data size (placeholder)
        
        *self.wav_writer.lock().await = Some(writer);
        println!("‚úÖ WAV writer initialized: {}", wav_path.display());
        
        Ok(())
    }

    async fn process_received_audio(&self, encoded_data: &[u8]) -> Result<(), Box<dyn std::error::Error>> {
        // Decode with G.711
        let mut encoder = self.g711_encoder.lock().await;
        match encoder.decode(encoded_data) {
            Ok(decoded_frame) => {
                // Write to WAV file
                if let Some(writer) = self.wav_writer.lock().await.as_mut() {
                    for sample in &decoded_frame.samples {
                        writer.write_all(&sample.to_le_bytes())?;
                    }
                }
                
                // Store in memory for analysis
                self.received_audio.lock().await.extend(&decoded_frame.samples);
                
                // Update statistics
                let mut stats = self.stats.write().await;
                stats.audio_frames_decoded += 1;
                stats.bytes_received += encoded_data.len() as u64;
                
                Ok(())
            }
            Err(e) => {
                eprintln!("‚ùå G.711 decoding failed: {}", e);
                Err(e.into())
            }
        }
    }

    async fn process_received_audio_frame(&self, audio_frame: rvoip_session_core::api::types::AudioFrame) -> Result<(), Box<dyn std::error::Error>> {
        // Session-core AudioFrame already has i16 samples
        let samples: Vec<i16> = audio_frame.samples.clone();
        
        // Write to WAV file
        if let Some(writer) = self.wav_writer.lock().await.as_mut() {
            for sample in &samples {
                writer.write_all(&sample.to_le_bytes())?;
            }
        }
        
        // Store in memory for analysis
        self.received_audio.lock().await.extend(&samples);
        
        // Update statistics
        let mut stats = self.stats.write().await;
        stats.audio_frames_decoded += 1;
        stats.rtp_packets_received += 1;
        stats.bytes_received += samples.len() as u64 * 2; // 2 bytes per sample
        
        if stats.audio_frames_decoded % 100 == 0 {
            println!("üì• Received {} audio frames", stats.audio_frames_decoded);
        }
        
        Ok(())
    }

    async fn finalize_wav_file(&self) -> Result<(), Box<dyn std::error::Error>> {
        let mut writer_guard = self.wav_writer.lock().await;
        if let Some(writer) = writer_guard.take() {
            writer.into_inner()?.flush()?;
            
            // Update WAV header with correct sizes
            let received_audio = self.received_audio.lock().await;
            let data_size = received_audio.len() * 2; // 16-bit samples
            let file_size = 36 + data_size;
            
            let wav_path = PathBuf::from("tests/output_real_network_audio.wav");
            let mut file = std::fs::OpenOptions::new().write(true).open(&wav_path)?;
            
            // Update file size at offset 4
            file.seek(std::io::SeekFrom::Start(4))?;
            file.write_all(&(file_size as u32).to_le_bytes())?;
            
            // Update data size at offset 40
            file.seek(std::io::SeekFrom::Start(40))?;
            file.write_all(&(data_size as u32).to_le_bytes())?;
            
            let mut stats = self.stats.write().await;
            stats.audio_file_created = true;
            
            println!("‚úÖ WAV file finalized: {} ({} samples, {} bytes)", 
                     wav_path.display(), received_audio.len(), data_size);
        }
        
        Ok(())
    }

    async fn get_stats(&self) -> TestStats {
        self.stats.read().await.clone()
    }
}

#[async_trait::async_trait]
impl ClientEventHandler for ClientBEventHandler {
    async fn on_incoming_call(&self, call_info: IncomingCallInfo) -> CallAction {
        println!("üìû Client B - Incoming call: {}", call_info.call_id);
        
        // Store call ID
        *self.call_id.write().await = Some(call_info.call_id.clone());
        
        // Initialize WAV writer
        if let Err(e) = self.initialize_wav_writer().await {
            eprintln!("‚ùå Failed to initialize WAV writer: {}", e);
            return CallAction::Reject;
        }
        
        CallAction::Accept
    }

    async fn on_call_state_changed(&self, status_info: CallStatusInfo) {
        println!("üìû Client B - Call {} state: {:?}", status_info.call_id, status_info.new_state);
        
        if status_info.new_state == CallState::Connected {
            let mut stats = self.stats.write().await;
            stats.call_established = true;
            
            // Start receiving audio frames
            let client_manager = self.client_manager.read().await;
            if let Some(client) = client_manager.as_ref() {
                // Subscribe to incoming audio frames
                match client.subscribe_to_audio_frames(&status_info.call_id).await {
                    Ok(mut frame_subscriber) => {
                        let self_clone = Arc::new(self.clone());
                        tokio::spawn(async move {
                            while let Ok(audio_frame) = frame_subscriber.recv() {
                                // Process the received audio frame
                                if let Err(e) = self_clone.process_received_audio_frame(audio_frame).await {
                                    eprintln!("‚ùå Failed to process received audio frame: {}", e);
                                }
                            }
                        });
                    }
                    Err(e) => {
                        eprintln!("‚ùå Failed to subscribe to audio frames: {}", e);
                    }
                }
            }
        } else if status_info.new_state == CallState::Terminated {
            // Finalize WAV file
            if let Err(e) = self.finalize_wav_file().await {
                eprintln!("‚ùå Failed to finalize WAV file: {}", e);
            }
        }
    }

    async fn on_media_event(&self, event: MediaEventInfo) {
        if matches!(event.event_type, MediaEventType::MediaSessionStarted { .. }) {
            // Update statistics
            let mut stats = self.stats.write().await;
            stats.rtp_packets_received += 1;
            
            // Note: Audio frame processing is now handled via subscribe_to_audio_frames
            // in the on_call_state_changed method
        }
    }

    async fn on_registration_status_changed(&self, _status_info: rvoip_client_core::events::RegistrationStatusInfo) {
        // Not used in this test
    }

    async fn on_client_error(&self, error: ClientError, call_id: Option<CallId>) {
        eprintln!("‚ùå Client B error: {} (call: {:?})", error, call_id);
    }

    async fn on_network_event(&self, connected: bool, reason: Option<String>) {
        println!("üåê Client B network event: connected={}, reason={:?}", connected, reason);
    }
}

/// Test implementation
#[tokio::test]
async fn test_real_network_peer_to_peer_audio_transmission() {
    println!("üöÄ Starting Real Network Peer-to-Peer Audio Transmission Test");
    println!("===============================================================");
    
    // Initialize logging
    let _ = tracing_subscriber::fmt()
        .with_env_filter("rvoip_client_core=debug,rvoip_session_core=debug")
        .with_test_writer()
        .try_init();
    
    // Create Client A (sender)
    println!("\nüîß Creating Client A (Audio Sender)...");
    let client_a_handler = Arc::new(ClientAEventHandler::new());
    
    // Load MP3 audio data
    if let Err(e) = client_a_handler.load_mp3_audio().await {
        eprintln!("‚ùå Failed to load audio: {}", e);
        assert!(false, "Failed to load audio data");
    }
    
    let client_a = ClientBuilder::new()
        .local_address(format!("127.0.0.1:{}", CLIENT_A_SIP_PORT).parse().unwrap())
        .media_address(format!("127.0.0.1:{}", CLIENT_A_MEDIA_PORT).parse().unwrap())
        .domain("test.local".to_string())
        .user_agent("RealNetworkTestClientA/1.0".to_string())
        .with_media(|m| m
            .codecs(vec!["PCMU".to_string()])
            .require_srtp(false)
            .echo_cancellation(false)
            .noise_suppression(false)
        )
        .rtp_ports(CLIENT_A_MEDIA_PORT, CLIENT_A_MEDIA_PORT + 100)
        .max_concurrent_calls(1)
        .build()
        .await
        .expect("Failed to create Client A");
    
    client_a_handler.set_client_manager(client_a.clone()).await;
    client_a.set_event_handler(client_a_handler.clone()).await;
    
    // Create Client B (receiver)
    println!("\nüîß Creating Client B (Audio Receiver)...");
    let client_b_handler = Arc::new(ClientBEventHandler::new());
    
    let client_b = ClientBuilder::new()
        .local_address(format!("127.0.0.1:{}", CLIENT_B_SIP_PORT).parse().unwrap())
        .media_address(format!("127.0.0.1:{}", CLIENT_B_MEDIA_PORT).parse().unwrap())
        .domain("test.local".to_string())
        .user_agent("RealNetworkTestClientB/1.0".to_string())
        .with_media(|m| m
            .codecs(vec!["PCMU".to_string()])
            .require_srtp(false)
            .echo_cancellation(false)
            .noise_suppression(false)
        )
        .rtp_ports(CLIENT_B_MEDIA_PORT, CLIENT_B_MEDIA_PORT + 100)
        .max_concurrent_calls(1)
        .build()
        .await
        .expect("Failed to create Client B");
    
    client_b_handler.set_client_manager(client_b.clone()).await;
    client_b.set_event_handler(client_b_handler.clone()).await;
    
    // Start both clients
    println!("\n‚ñ∂Ô∏è  Starting SIP clients...");
    client_a.start().await.expect("Failed to start Client A");
    client_b.start().await.expect("Failed to start Client B");
    
    // Wait for clients to initialize
    sleep(Duration::from_secs(2)).await;
    
    // Client A makes a call to Client B
    println!("\nüìû Client A calling Client B...");
    let from_uri = format!("sip:clienta@127.0.0.1:{}", CLIENT_A_SIP_PORT);
    let to_uri = format!("sip:clientb@127.0.0.1:{}", CLIENT_B_SIP_PORT);
    
    let call_id = client_a.make_call(from_uri, to_uri, None).await
        .expect("Failed to make call");
    
    println!("‚úÖ Call initiated with ID: {}", call_id);
    
    // Wait for call to establish and audio to transmit
    println!("\n‚è≥ Waiting for call establishment and audio transmission...");
    sleep(Duration::from_secs(5)).await;
    
    // Check if call is established
    let stats_a = client_a_handler.get_stats().await;
    let stats_b = client_b_handler.get_stats().await;
    
    assert!(stats_a.call_established, "Call not established on Client A");
    assert!(stats_b.call_established, "Call not established on Client B");
    
    println!("‚úÖ Call established successfully");
    
    // Let audio transmission run for the test duration
    println!("\nüéµ Audio transmission in progress...");
    sleep(Duration::from_secs(TEST_DURATION_SECS)).await;
    
    // Shutdown audio transmission
    client_a_handler.shutdown().await;
    
    // Hang up the call
    println!("\nüìû Hanging up call...");
    client_a.hangup_call(&call_id).await
        .expect("Failed to hang up call");
    
    // Wait for cleanup
    sleep(Duration::from_secs(2)).await;
    
    // Get final statistics
    let final_stats_a = client_a_handler.get_stats().await;
    let final_stats_b = client_b_handler.get_stats().await;
    
    // Print test results
    println!("\nüìä Test Results:");
    println!("================");
    println!("Client A (Sender):");
    println!("  Audio frames encoded: {}", final_stats_a.audio_frames_encoded);
    println!("  RTP packets sent: {}", final_stats_a.rtp_packets_sent);
    println!("  Bytes transmitted: {}", final_stats_a.bytes_transmitted);
    
    println!("\nClient B (Receiver):");
    println!("  Audio frames decoded: {}", final_stats_b.audio_frames_decoded);
    println!("  RTP packets received: {}", final_stats_b.rtp_packets_received);
    println!("  Bytes received: {}", final_stats_b.bytes_received);
    println!("  WAV file created: {}", final_stats_b.audio_file_created);
    
    // Verify test success
    assert!(final_stats_a.audio_frames_encoded > 0, "No audio frames were encoded");
    assert!(final_stats_a.rtp_packets_sent > 0, "No RTP packets were sent");
    assert!(final_stats_b.rtp_packets_received > 0, "No RTP packets were received");
    assert!(final_stats_b.audio_file_created, "WAV file was not created");
    
    // Verify WAV file exists and has reasonable size
    let wav_path = PathBuf::from("tests/output_real_network_audio.wav");
    assert!(wav_path.exists(), "WAV file does not exist");
    
    let file_size = std::fs::metadata(&wav_path)
        .expect("Failed to get WAV file metadata")
        .len();
    
    assert!(file_size > 44, "WAV file is too small (no audio data)");
    
    println!("\n‚úÖ Test completed successfully!");
    println!("   WAV file created: {} ({} bytes)", wav_path.display(), file_size);
    println!("   Audio transmission: {} frames encoded, {} frames decoded", 
             final_stats_a.audio_frames_encoded, final_stats_b.audio_frames_decoded);
    println!("   Network transmission: {} packets sent, {} packets received",
             final_stats_a.rtp_packets_sent, final_stats_b.rtp_packets_received);
} 